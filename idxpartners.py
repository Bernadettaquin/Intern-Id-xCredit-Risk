# -*- coding: utf-8 -*-
"""idxpartners.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rH5MQ2gPmkXTUwJg4wrACUIZKxSdnKf6

IDX PARTNERS
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

df = pd.read_csv('/content/loan_data_2007_2014.csv')
df.head()

df.info()
df.duplicated().sum()
df.drop_duplicates(inplace=True)
df.duplicated().sum()

# Mengecek Missing Values
missing_values = df.isnull().sum()
missing_percentage = (missing_values / len(df)) * 100
missing_data = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})
missing_data = missing_data[missing_data['Missing Values'] > 0]
print("Missing Values:")
print(missing_data)

missing_values = df.isnull().sum()
missing_values

# Mengecek Inconsistent Entries
print("\nUnique values in categorical columns:")
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    print(f"{col}: {df[col].unique()[:10]}")  # Menampilkan 10 nilai unik pertama

# Outlier
numeric_cols = df.select_dtypes(include=[np.number]).columns
num_cols = len(numeric_cols)
fig, axes = plt.subplots(nrows=(num_cols // 3) + 1, ncols=3, figsize=(15, 5 * ((num_cols // 3) + 1)))
axes = axes.flatten()

for i, col in enumerate(numeric_cols):
    sns.boxplot(y=df[col], ax=axes[i])
    axes[i].set_title(col)

# Hapus subplot kosong jika ada
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

#  Mendeteksi Outlier Menggunakan IQR
def detect_outliers_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
    return outliers

outlier_counts = {}
for col in numeric_cols:
    outliers = detect_outliers_iqr(df, col)
    outlier_counts[col] = len(outliers)

print("\nJumlah outliers per kolom (IQR Method):")
print(outlier_counts)

numeric_columns = [
    "loan_amnt",
    "funded_amnt",
    "int_rate",
    "installment",
    "annual_inc",
    "dti",
    "open_acc",
    "revol_bal",
    "total_acc",
    "pub_rec",
    "recoveries",
    "total_pymnt",
]

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Set style seaborn
sns.set(style="whitegrid")

# Pilih kolom numerik yang ada di dataset
numeric_columns = [
    "loan_amnt", "funded_amnt", "int_rate", "installment", "annual_inc",
    "dti", "open_acc", "revol_bal", "total_acc", "pub_rec", "recoveries", "total_pymnt"
]

# ---  UNIVARIATE ANALYSIS ---
##  Histogram untuk melihat distribusi data
plt.figure(figsize=(12, 8))
df[numeric_columns].hist(bins=30, figsize=(12, 8), layout=(4, 3), edgecolor="black")
plt.tight_layout()
plt.show()

##  Boxplot untuk melihat outlier
plt.figure(figsize=(12, 6))
sns.boxplot(data=df[numeric_columns])
plt.xticks(rotation=45)
plt.title("Boxplot Variabel Numerik")
plt.show()

# ---  BIVARIATE ANALYSIS ---
##  Korelasi antar variabel numerik
plt.figure(figsize=(10, 6))
sns.heatmap(df[numeric_columns].corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Heatmap Korelasi Variabel Numerik")
plt.show()

##  Scatterplot antara Suku Bunga dan DTI
plt.figure(figsize=(8, 6))
sns.scatterplot(x=df["dti"], y=df["int_rate"], alpha=0.5)
plt.xlabel("Debt-to-Income Ratio")
plt.ylabel("Interest Rate")
plt.title("Hubungan DTI dengan Suku Bunga")
plt.show()

# --- MULTIVARIATE ANALYSIS ---
##  Pairplot untuk melihat pola hubungan antar variabel
selected_columns = ["loan_amnt", "int_rate", "installment", "dti", "total_pymnt"]
sns.pairplot(df[selected_columns], diag_kind="kde", corner=True)
plt.show()

#Data Cleaning and Handling Missing Values
# Mengecek jumlah missing values
print(df.isnull().sum())

# Menghapus kolom dengan terlalu banyak missing values
df.dropna(axis=1, thresh=len(df)*0.5, inplace=True)  # Hapus kolom dengan >50% missing


# Mengisi missing values numerik dengan median
df.fillna(df.median(numeric_only=True), inplace=True)

# Mengisi missing values kategorik dengan mode
for col in df.select_dtypes(include=['object']):
    df[col] = df[col].fillna(df[col].mode()[0])

#feature selection
selected_features = [
    "loan_amnt", "int_rate", "installment", "annual_inc", "dti",
    "open_acc", "total_acc", "revol_bal", "pub_rec", "recoveries", "term", "grade",
    "verification_status", "purpose", "loan_status"
]
df = df[selected_features]
df

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
numerical_features = ["loan_amnt", "int_rate", "installment", "annual_inc", "dti"]
df[numerical_features] = scaler.fit_transform(df[numerical_features])

from sklearn.preprocessing import LabelEncoder

categorical_features = ["term", "grade", "verification_status", "purpose"]
encoder = LabelEncoder()

for col in categorical_features:
    df[col] = encoder.fit_transform(df[col])

df["loan_to_income_ratio"] = df["loan_amnt"] / df["annual_inc"]
#feature creation
df

#pisah data training dan testing
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pandas as pd

X = df.drop(columns=["loan_status"])  # Fitur
y = df["loan_status"]  # Target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

log_model = LogisticRegression(max_iter=1000)
log_model.fit(X_train_scaled, y_train)

#Decision Tree
tree_model = DecisionTreeClassifier()
tree_model.fit(X_train, y_train)

#Random Forest
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

log_pred = log_model.predict(X_test)
log_acc = accuracy_score(y_test, log_pred)

tree_pred = tree_model.predict(X_test)
tree_acc = accuracy_score(y_test, tree_pred)

rf_pred = rf_model.predict(X_test)
rf_acc = accuracy_score(y_test, rf_pred)

# Buat DataFrame untuk membandingkan akurasi ketiga model
model_comparison = pd.DataFrame({
    "Model": ["Logistic Regression", "Decision Tree", "Random Forest"],
    "Accuracy": [log_acc, tree_acc, rf_acc]
})

# Tampilkan hasil
print(model_comparison)

# Ambil Feature Importance dari Random Forest
feature_importance = rf_model.feature_importances_

# Buat DataFrame untuk mempermudah visualisasi
importance_df = pd.DataFrame({
    "Feature": X.columns,
    "Importance": feature_importance
}).sort_values(by="Importance", ascending=False)

# Tampilkan 10 fitur terpenting
print(importance_df.head(10))

plt.figure(figsize=(10, 6))
plt.barh(importance_df["Feature"][:10], importance_df["Importance"][:10], color='skyblue')
plt.xlabel("Importance Score")
plt.ylabel("Feature Name")
plt.title("Top 10 Feature Importances - Random Forest")
plt.gca().invert_yaxis()  # Membalik urutan agar fitur terpenting di atas
plt.show()